{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhikasharma-0203/Reinforcement-Learning-21csu462/blob/main/greedy%2Coptimistic%2Ceplsilon_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "920873fc",
      "metadata": {
        "id": "920873fc"
      },
      "source": [
        "# Greedy Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da49882",
      "metadata": {
        "id": "7da49882",
        "outputId": "6f14f335-b0e5-4ec1-c7bc-832aacfb3d7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average reward using Greedy Approach: 7.0\n",
            "Lamp chosen 0\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def greedy_approach(lamp_durations):\n",
        "    best_lamp = None\n",
        "    max_duration = 0\n",
        "\n",
        "    for lamp, duration in enumerate(lamp_durations):\n",
        "        if duration > max_duration:\n",
        "            max_duration = duration\n",
        "            best_lamp = lamp\n",
        "\n",
        "    return best_lamp\n",
        "\n",
        "num_lamps = 5\n",
        "lamp_durations = [random.randint(1, 10) for i in range(num_lamps)]  # Generate random durations\n",
        "steps = 1000\n",
        "\n",
        "total_reward = 0\n",
        "for i in range(steps):\n",
        "    chosen_lamp = greedy_approach(lamp_durations)\n",
        "    reward = lamp_durations[chosen_lamp]\n",
        "    total_reward += reward\n",
        "\n",
        "average_reward = total_reward / steps\n",
        "print(\"Average reward using Greedy Approach:\", average_reward)\n",
        "print(\"Lamp chosen\",chosen_lamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e5f0469",
      "metadata": {
        "id": "8e5f0469"
      },
      "source": [
        "# Optimistic approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae86ea4b",
      "metadata": {
        "id": "ae86ea4b",
        "outputId": "68ffcc58-0f24-4fbc-d07e-fab1bee01c87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average reward using Optimistic Approach: 4.399\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def optimistic_approach(lamp_durations):\n",
        "    num_lamps = len(lamp_durations)\n",
        "    estimated_durations = [10] * num_lamps  # Initialize with optimistic estimates\n",
        "    chosen_lamp = None\n",
        "\n",
        "    for lamp, _ in enumerate(lamp_durations):\n",
        "        observed_duration = random.randint(1, 10)  # Generate random observed duration\n",
        "        estimated_durations[lamp] = observed_duration\n",
        "\n",
        "    for _ in range(steps):\n",
        "        chosen_lamp = estimated_durations.index(max(estimated_durations))\n",
        "        reward = lamp_durations[chosen_lamp]\n",
        "        observed_duration = random.randint(1, 10)  # Generate random observed duration\n",
        "        estimated_durations[chosen_lamp] = (estimated_durations[chosen_lamp] + observed_duration) / 2\n",
        "\n",
        "    return chosen_lamp\n",
        "\n",
        "num_lamps = 5\n",
        "lamp_durations = [random.randint(1, 10) for _ in range(num_lamps)]  # Generate random durations\n",
        "steps = 1000\n",
        "\n",
        "total_reward = 0\n",
        "for _ in range(steps):\n",
        "    chosen_lamp = optimistic_approach(lamp_durations)\n",
        "    reward = lamp_durations[chosen_lamp]\n",
        "    total_reward += reward\n",
        "\n",
        "average_reward = total_reward / steps\n",
        "print(\"Average reward using Optimistic Approach:\", average_reward)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08184865",
      "metadata": {
        "id": "08184865"
      },
      "source": [
        "# Epsilon approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24344702",
      "metadata": {
        "id": "24344702",
        "outputId": "00d0b866-f61f-45d4-891d-0e4b1967168b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average reward using Epsilon-Greedy Approach: 5.494498984855704\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def epsilon_greedy_approach(lamp_durations, epsilon):\n",
        "    num_lamps = len(lamp_durations)\n",
        "    chosen_lamp = None\n",
        "\n",
        "    for _ in range(steps):\n",
        "        if random.random() < epsilon:\n",
        "            chosen_lamp = random.randint(0, num_lamps - 1)\n",
        "        else:\n",
        "            chosen_lamp = lamp_durations.index(max(lamp_durations))\n",
        "        reward = lamp_durations[chosen_lamp]\n",
        "        observed_duration = random.randint(1, 10)  # Generate random observed duration\n",
        "        lamp_durations[chosen_lamp] = (lamp_durations[chosen_lamp] + observed_duration) / 2\n",
        "\n",
        "    return chosen_lamp\n",
        "\n",
        "num_lamps = 5\n",
        "lamp_durations = [random.randint(1, 10) for _ in range(num_lamps)]  # Generate random durations\n",
        "steps = 1000\n",
        "exploration_probability = 0.1  # Set epsilon value\n",
        "\n",
        "total_reward = 0\n",
        "for _ in range(steps):\n",
        "    chosen_lamp = epsilon_greedy_approach(lamp_durations, exploration_probability)\n",
        "    reward = lamp_durations[chosen_lamp]\n",
        "    total_reward += reward\n",
        "\n",
        "average_reward = total_reward / steps\n",
        "print(\"Average reward using Epsilon-Greedy Approach:\", average_reward)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}